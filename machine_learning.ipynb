{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from MachineLearning import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================================================\n",
      "Checking base balance: \n",
      "                target_local  target_global\n",
      "FALSE POSITIVE          4744           4215\n",
      "CONFIRMED               2639           2429\n"
     ]
    }
   ],
   "source": [
    "local_view = pd.read_csv(\n",
    "    \"Preprocessed\\preprocessed_local_view.csv\", sep=\",\")\n",
    "global_view = pd.read_csv(\n",
    "    \"Preprocessed\\preprocessed_global_view.csv\", sep=\",\")\n",
    "\n",
    "local_view.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "global_view.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "\n",
    "dropna_list = [local_view, global_view]\n",
    "\n",
    "for var in dropna_list:\n",
    "    var.dropna(inplace=True)\n",
    "    \n",
    "print(\"\\n============================================================================================================\")\n",
    "print(\"Checking base balance: \")\n",
    "\n",
    "targets = pd.concat([local_view[['label']].rename(columns={'label': 'target_local'}), global_view[[\n",
    "                    'label']].rename(columns={'label': 'target_global'})], axis=0, ignore_index=True)\n",
    "counts = targets.apply(pd.Series.value_counts).fillna(0).astype(int)\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform target column values ​​into 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = {'CONFIRMED': 0, 'FALSE POSITIVE': 1}\n",
    "local_view['label'] = local_view['label'].map(target_map)\n",
    "global_view['label'] = global_view['label'].map(target_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= Separating into X and y =============\n",
    "\n",
    "X_local = local_view.iloc[:, :-1]\n",
    "X_global = global_view.iloc[:, :-1]\n",
    "\n",
    "y_local = local_view['label']\n",
    "y_global = global_view['label']\n",
    "\n",
    "# ============= Separating into training and testing =============\n",
    "\n",
    "X_train_local, X_test_local, y_train_local, y_test_local = train_test_split(\n",
    "    X_local, y_local, test_size= 0.3, random_state=42, stratify=y_local)\n",
    "\n",
    "X_train_global, X_test_global, y_train_global, y_test_global = train_test_split(\n",
    "    X_global, y_global, test_size= 0.3, random_state=42, stratify=y_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smote balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smote balancing\n",
    "smote = SMOTE()  # Create a SMOTE instance\n",
    "X_train_local, y_train_local = smote.fit_resample(X_train_local, y_train_local)  # Apply SMOTE to data local\n",
    "X_train_global, y_train_global = smote.fit_resample(X_train_global, y_train_global)  # Apply SMOTE to data global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All models and parameters of classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_parameters_C = {\n",
    "    'AdaBoostClassifier': {\n",
    "        'clf': AdaBoostClassifier(random_state=42),\n",
    "        'parameters': {\n",
    "            'n_estimators': range(60, 220, 40)\n",
    "        },\n",
    "    },\n",
    "    'XGBClassifier': {\n",
    "        'clf': xgb.XGBClassifier(objective = \"binary:logistic\", random_state=42),\n",
    "        'parameters': {\n",
    "            'min_child_weight': [1, 5, 10],\n",
    "            'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "            'max_depth': [3, 4, 5]\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'clf': SVC(probability=True, random_state=42),\n",
    "        'parameters': {\n",
    "            'C': [1, 3, 5, 10, 15],\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'tol': [1e-3, 1e-4]\n",
    "        },\n",
    "    },\n",
    "    'MLPClassifier': {\n",
    "        'clf': MLPClassifier(random_state=42),\n",
    "        'parameters': {\n",
    "            'solver': ['sgd', 'adam'], \n",
    "            'max_iter': [1000, 1300, 1500, 2000], \n",
    "            'alpha': 10.0 ** -np.arange(1, 10), \n",
    "            'hidden_layer_sizes':np.arange(10, 15),\n",
    "            'tol': [1e-3, 1e-4]\n",
    "        },\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.defining_classifiers(models_and_parameters_C, X_train_local, y_train_local, X_test_local, y_test_local, \"local\")\n",
    "# models.defining_classifiers(models_and_parameters_C, X_train_global, y_train_global, X_test_global, y_test_global, \"global\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  1.837927  1.802662  1.232059  1.512449  1.569320  1.405640  1.000000   \n",
      "1  1.000000  1.476023  2.462279  1.453719  1.024518  1.866817  1.159148   \n",
      "2  1.078824  1.181373  2.207187  1.587193  0.980563  0.577552  1.163036   \n",
      "3  1.081321  1.580252  0.362759  0.644941  0.309738  0.704545  1.099352   \n",
      "4  0.680829  0.319184 -0.042460 -0.404105 -0.765749 -0.415386 -0.065023   \n",
      "\n",
      "          7         8         9  ...       191       192       193       194  \\\n",
      "0  1.496697  0.705534  1.123828  ...  1.601433  1.375619  1.492625  1.445211   \n",
      "1  1.171658  2.225083  2.339150  ...  1.587496 -0.104021  0.708417  2.168780   \n",
      "2  1.401895  2.084558  0.594387  ...  1.928679  0.972320  1.613166  2.017149   \n",
      "3  1.028856  0.958360  0.887864  ...  1.378002  1.048320  2.519353 -0.161869   \n",
      "4  0.285340  0.635703  0.986067  ...  1.318989  1.396417  1.473845  1.551273   \n",
      "\n",
      "        195       196       197       198       199       200  \n",
      "0  1.380684  1.362785  1.916510  1.369103  1.416069  1.081608  \n",
      "1  0.985443  1.935433  1.096555  0.834368  0.359093  1.717915  \n",
      "2  1.602650  0.453598  1.042030  1.886965  1.244905  1.336639  \n",
      "3  0.843370  0.423355  0.003339  2.488378  1.755441  1.723028  \n",
      "4  1.551273  1.551273  1.551273  1.551273  1.551273  1.551273  \n",
      "\n",
      "[5 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_local.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_local.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array list, no caso seria -> 201 instancias + label + 201 instancias + label + ...\n",
    "\n",
    "# uni_data = [[1.837927  1.802662  1.232059  1.512449 LABEL(1 or 0) 1.569320  1.405640  1.000000 1.551273 LABEL(1 or 0)]]\n",
    "\n",
    "uni_data = local_view.values\n",
    "\n",
    "# Usando numpy.ravel para transformar a matriz em um array unidimensional\n",
    "uni_data = uni_data.ravel()\n",
    "\n",
    "# As variáveis abaixo garantem padronização e reprodutibilidade\n",
    "\n",
    "TRAIN_SPLIT = 1038788\n",
    "\n",
    "# calcular numero de linhas \n",
    "# 7383 * 201 = 1.483.983 \n",
    "# Treino 70 % -> 1.038.788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_local, X_test_local, y_train_local, y_test_local = X_train_local.values.ravel(), X_test_local.values.ravel(), y_train_local.values.ravel(), y_test_local.values.ravel()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.83792682,  1.80266181,  1.23205949,  1.51244916,  1.56932018,\n",
       "        1.40564018,  1.        ,  1.49669697,  0.70553375,  1.12382756,\n",
       "        1.1114299 ,  1.44419017,  1.50309692,  2.12711933,  1.52828495,\n",
       "        1.16212154,  2.40785409,  1.51900931,  1.4633947 ,  1.76495743,\n",
       "        1.38783919,  1.25999072,  1.88723364,  1.70934591,  1.23361735,\n",
       "        1.42847913,  1.03088031,  1.17966405,  1.29297629,  1.17453201,\n",
       "        1.94744208,  1.68249518,  1.34438724,  2.08653443,  1.4763223 ,\n",
       "        2.11519395,  1.68377202,  1.97412647,  1.89862413,  1.11353673,\n",
       "        1.92158557,  0.84935254,  1.71099146,  1.92820263,  1.42726483,\n",
       "        0.99790787,  1.23127348,  1.25001944,  1.25288871,  1.32347451,\n",
       "        1.85450614,  0.96068753,  1.35640173,  0.51606193,  0.4945905 ,\n",
       "        0.23911974,  0.86746737, -0.16382229,  1.04232218,  0.33728038,\n",
       "        0.71143815,  0.45230076, -0.26494808,  0.60850513,  0.48261954,\n",
       "        0.63432782,  0.23709672,  0.21006438,  0.32733172, -0.47672702,\n",
       "       -0.22857101,  0.29916911, -0.38202974, -0.42276726, -0.22044406,\n",
       "        0.04385248,  0.25176829,  0.070973  ,  0.10602562,  0.13813654,\n",
       "        0.05956059, -0.28831945,  0.02806181,  0.04893361, -0.48424692,\n",
       "       -0.04476929, -0.54437563, -0.31445838,  0.62936731, -0.40519664,\n",
       "       -0.19697771, -0.1924929 ,  0.12332486, -0.31551674, -0.02650892,\n",
       "        0.21991494, -0.31597916,  0.16109463, -0.51847734,  0.41796978,\n",
       "        0.47848321,  0.28816076,  0.22897593, -0.19316939,  0.18722226,\n",
       "       -1.        , -0.65163117,  0.10295695, -0.13487109,  0.06408119,\n",
       "       -0.51763281, -0.12717164, -0.55349362, -0.00472225,  0.36391629,\n",
       "        0.36758326,  1.67819064, -0.24956422,  0.33528801, -0.37637151,\n",
       "        0.09373813,  0.82048737,  0.27135162, -0.27229745, -0.01128742,\n",
       "       -0.15188595, -0.0148454 ,  0.11577831,  0.41506291,  0.79225999,\n",
       "        0.06365319,  0.84126953,  0.55361028,  0.35560421,  0.0355277 ,\n",
       "        0.67910383,  0.39867769,  0.42320288,  0.09195752,  0.00365739,\n",
       "        0.33118497,  0.50094079,  0.37856564, -0.20227867,  1.01763432,\n",
       "        0.00401265,  0.81443163,  1.00285702,  1.33050115,  0.570414  ,\n",
       "        0.45772522,  1.05611631,  1.47104511,  1.01962361,  0.55060344,\n",
       "        1.52770506,  1.16677065,  1.7544149 ,  1.50072973,  1.51561518,\n",
       "        1.59985342,  1.23154162,  1.79755955,  1.14992515,  1.65127718,\n",
       "        1.53483888,  1.92316075,  1.3495986 ,  1.78314891,  1.18173649,\n",
       "        1.22574699,  0.97239276,  1.07812705,  1.59267119,  1.53493375,\n",
       "        2.19074862,  1.52519262,  1.86716404,  0.98336043,  1.63218774,\n",
       "        1.18493646,  1.83944987,  1.36014478,  1.46564392,  1.51947203,\n",
       "        1.70028767,  1.24075786,  1.1535663 ,  1.19444932,  1.6090625 ,\n",
       "        1.34143987,  1.60143297,  1.37561936,  1.49262476,  1.44521115,\n",
       "        1.38068352,  1.36278497,  1.91651026,  1.36910277,  1.4160694 ,\n",
       "        1.08160756,  0.        ,  1.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_data[:203]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 8)                 320       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 338\n",
      "Trainable params: 338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 2156, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5707, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alex-\\Desktop\\Dev\\Exoplanet-Detection-Algorithm\\machine_learning.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alex-/Desktop/Dev/Exoplanet-Detection-Algorithm/machine_learning.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m x_val_uni, y_val_uni \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39munivariate_data(uni_data, TRAIN_SPLIT, \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alex-/Desktop/Dev/Exoplanet-Detection-Algorithm/machine_learning.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                                     univariate_past_history,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alex-/Desktop/Dev/Exoplanet-Detection-Algorithm/machine_learning.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                     univariate_future_target)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alex-/Desktop/Dev/Exoplanet-Detection-Algorithm/machine_learning.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Test LSTM data local\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alex-/Desktop/Dev/Exoplanet-Detection-Algorithm/machine_learning.ipynb#X25sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# models.method_LSTM(X_train_local, y_train_local, X_test_local, y_test_local, univariate_past_history, future)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/alex-/Desktop/Dev/Exoplanet-Detection-Algorithm/machine_learning.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m models\u001b[39m.\u001b[39;49mmethod_LSTM(x_train_uni, y_train_uni, x_val_uni, y_val_uni, univariate_past_history, future)\n",
      "File \u001b[1;32mc:\\Users\\alex-\\Desktop\\Dev\\Exoplanet-Detection-Algorithm\\MachineLearning\\models.py:172\u001b[0m, in \u001b[0;36mmethod_LSTM\u001b[1;34m(x_train_uni, y_train_uni, x_val_uni, y_val_uni, univariate_past_history, future)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39m# Training LSTM\u001b[39;00m\n\u001b[0;32m    170\u001b[0m EPOCHS \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m--> 172\u001b[0m lstm_log \u001b[39m=\u001b[39m simple_lstm_model\u001b[39m.\u001b[39;49mfit(train_univariate, epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[0;32m    173\u001b[0m                                  validation_data\u001b[39m=\u001b[39;49mval_univariate, validation_steps\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[0;32m    175\u001b[0m plot_train_history_LSTM(lstm_log, \u001b[39m'\u001b[39m\u001b[39mLSTM Training and validation loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    177\u001b[0m future \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegswisu8w.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 2156, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5707, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n"
     ]
    }
   ],
   "source": [
    "'''Tamanho da Janela do Historico'''\n",
    "univariate_past_history = 201\n",
    "future = univariate_future_target = 1\n",
    "\n",
    "x_train_uni, y_train_uni = models.univariate_data(uni_data, 0, TRAIN_SPLIT,\n",
    "                                        univariate_past_history,\n",
    "                                        univariate_future_target)\n",
    "x_val_uni, y_val_uni = models.univariate_data(uni_data, TRAIN_SPLIT, None,\n",
    "                                    univariate_past_history,\n",
    "                                    univariate_future_target)\n",
    "\n",
    "\n",
    "# Test LSTM data local\n",
    "# models.method_LSTM(X_train_local, y_train_local, X_test_local, y_test_local, univariate_past_history, future)\n",
    "models.method_LSTM(x_train_uni, y_train_uni, x_val_uni, y_val_uni, univariate_past_history, future)\n",
    "\n",
    "# Test LSTM data global\n",
    "# models.method_LSTM(x_train_uni, y_train_uni, x_val_uni, y_val_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
