{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from MachineLearning import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================================================\n",
      "Checking base balance: \n",
      "                target_local  target_global\n",
      "FALSE POSITIVE          4744           4215\n",
      "CONFIRMED               2639           2429\n"
     ]
    }
   ],
   "source": [
    "local_view = pd.read_csv(\n",
    "    \"Preprocessed\\preprocessed_local_view.csv\", sep=\",\")\n",
    "global_view = pd.read_csv(\n",
    "    \"Preprocessed\\preprocessed_global_view.csv\", sep=\",\")\n",
    "\n",
    "local_view.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "global_view.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "\n",
    "dropna_list = [local_view, global_view]\n",
    "\n",
    "for var in dropna_list:\n",
    "    var.dropna(inplace=True)\n",
    "    \n",
    "print(\"\\n============================================================================================================\")\n",
    "print(\"Checking base balance: \")\n",
    "\n",
    "targets = pd.concat([local_view[['label']].rename(columns={'label': 'target_local'}), global_view[[\n",
    "                    'label']].rename(columns={'label': 'target_global'})], axis=0, ignore_index=True)\n",
    "counts = targets.apply(pd.Series.value_counts).fillna(0).astype(int)\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform target column values ​​into 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = {'CONFIRMED': 0, 'FALSE POSITIVE': 1}\n",
    "local_view['label'] = local_view['label'].map(target_map)\n",
    "global_view['label'] = global_view['label'].map(target_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= Separating into X and y =============\n",
    "\n",
    "X_local = local_view.iloc[:, :-1]\n",
    "X_global = global_view.iloc[:, :-1]\n",
    "\n",
    "y_local = local_view['label']\n",
    "y_global = global_view['label']\n",
    "\n",
    "# ============= Separating into training and testing =============\n",
    "\n",
    "X_train_local, X_test_local, y_train_local, y_test_local = train_test_split(\n",
    "    X_local, y_local, test_size= 0.3, random_state=42, stratify=y_local)\n",
    "\n",
    "X_train_global, X_test_global, y_train_global, y_test_global = train_test_split(\n",
    "    X_global, y_global, test_size= 0.3, random_state=42, stratify=y_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smote balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smote balancing\n",
    "smote = SMOTE()  # Create a SMOTE instance\n",
    "X_train_local, y_train_local = smote.fit_resample(X_train_local, y_train_local)  # Apply SMOTE to data local\n",
    "X_train_global, y_train_global = smote.fit_resample(X_train_global, y_train_global)  # Apply SMOTE to data global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All models and parameters of classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_parameters_C = {\n",
    "    'AdaBoostClassifier': {\n",
    "        'clf': AdaBoostClassifier(random_state=42),\n",
    "        'parameters': {\n",
    "            'n_estimators': range(60, 220, 40)\n",
    "        },\n",
    "    },\n",
    "    'XGBClassifier': {\n",
    "        'clf': xgb.XGBClassifier(objective = \"binary:logistic\", random_state=42),\n",
    "        'parameters': {\n",
    "            'min_child_weight': [1, 5, 10],\n",
    "            'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "            'max_depth': [3, 4, 5]\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'clf': SVC(probability=True, random_state=42),\n",
    "        'parameters': {\n",
    "            'C': [1, 3, 5, 10, 15],\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'tol': [1e-3, 1e-4]\n",
    "        },\n",
    "    },\n",
    "    'MLPClassifier': {\n",
    "        'clf': MLPClassifier(random_state=42),\n",
    "        'parameters': {\n",
    "            'solver': ['sgd', 'adam'], \n",
    "            'max_iter': [1000, 1300, 1500, 2000], \n",
    "            'alpha': 10.0 ** -np.arange(1, 10), \n",
    "            'hidden_layer_sizes':np.arange(10, 15),\n",
    "            'tol': [1e-3, 1e-4]\n",
    "        },\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.defining_classifiers(models_and_parameters_C, X_train_local, y_train_local, X_test_local, y_test_local, \"local\")\n",
    "# models.defining_classifiers(models_and_parameters_C, X_train_global, y_train_global, X_test_global, y_test_global, \"global\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_local\n",
    "data.index =  y_local\n",
    "uni_data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As variáveis abaixo garantem padronização e reprodutibilidade\n",
    "TRAIN_SPLIT = 300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 6030 into shape (30,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m univariate_past_history \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m  \u001b[39m#30 observacoes anteriores\u001b[39;00m\n\u001b[0;32m      3\u001b[0m future \u001b[39m=\u001b[39m univariate_future_target \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m  \u001b[39m#a proxima observação\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m x_train_uni, y_train_uni \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39;49munivariate_data(uni_data, \u001b[39m0\u001b[39;49m, TRAIN_SPLIT,\n\u001b[0;32m      6\u001b[0m                                         univariate_past_history,\n\u001b[0;32m      7\u001b[0m                                         univariate_future_target)\n\u001b[0;32m      8\u001b[0m x_val_uni, y_val_uni \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39munivariate_data(uni_data, TRAIN_SPLIT, \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m                                     univariate_past_history,\n\u001b[0;32m     10\u001b[0m                                     univariate_future_target)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Test LSTM data local\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alex-\\Desktop\\Dev\\Exoplanet-Detection-Algorithm\\MachineLearning\\models.py:133\u001b[0m, in \u001b[0;36munivariate_data\u001b[1;34m(dataset, start_index, end_index, history_size, target_size)\u001b[0m\n\u001b[0;32m    131\u001b[0m     indices \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(i\u001b[39m-\u001b[39mhistory_size, i)\n\u001b[0;32m    132\u001b[0m     \u001b[39m# Reshape data from (history_size,) to (history_size, 1)\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     data\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39;49mreshape(dataset[indices], (history_size, \u001b[39m1\u001b[39;49m)))\n\u001b[0;32m    134\u001b[0m     labels\u001b[39m.\u001b[39mappend(dataset[i\u001b[39m+\u001b[39mtarget_size])\n\u001b[0;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(data), np\u001b[39m.\u001b[39marray(labels)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(a, newshape, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    200\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mreshape\u001b[39;49m\u001b[39m'\u001b[39;49m, newshape, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[1;32mc:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 6030 into shape (30,1)"
     ]
    }
   ],
   "source": [
    "'''Tamanho da Janela do Historico'''\n",
    "univariate_past_history = 30  #30 observacoes anteriores\n",
    "future = univariate_future_target = 5  #a proxima observação\n",
    "\n",
    "x_train_uni, y_train_uni = models.univariate_data(uni_data, 0, TRAIN_SPLIT,\n",
    "                                        univariate_past_history,\n",
    "                                        univariate_future_target)\n",
    "x_val_uni, y_val_uni = models.univariate_data(uni_data, TRAIN_SPLIT, None,\n",
    "                                    univariate_past_history,\n",
    "                                    univariate_future_target)\n",
    "\n",
    "\n",
    "# Test LSTM data local\n",
    "models.method_LSTM(x_train_uni, y_train_uni, x_val_uni, y_val_uni)\n",
    "\n",
    "# Test LSTM data global\n",
    "# models.method_LSTM(x_train_uni, y_train_uni, x_val_uni, y_val_uni)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
