{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from MachineLearning import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================================================\n",
      "Checking base balance: \n",
      "                target_local  target_global\n",
      "FALSE POSITIVE          4744           4215\n",
      "CONFIRMED               2639           2429\n"
     ]
    }
   ],
   "source": [
    "local_view = pd.read_csv(\n",
    "    \"Preprocessed\\preprocessed_local_view.csv\", sep=\",\")\n",
    "global_view = pd.read_csv(\n",
    "    \"Preprocessed\\preprocessed_global_view.csv\", sep=\",\")\n",
    "\n",
    "local_view.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "global_view.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "\n",
    "dropna_list = [local_view, global_view]\n",
    "\n",
    "for var in dropna_list:\n",
    "    var.dropna(inplace=True)\n",
    "    \n",
    "print(\"\\n============================================================================================================\")\n",
    "print(\"Checking base balance: \")\n",
    "\n",
    "targets = pd.concat([local_view[['label']].rename(columns={'label': 'target_local'}), global_view[[\n",
    "                    'label']].rename(columns={'label': 'target_global'})], axis=0, ignore_index=True)\n",
    "counts = targets.apply(pd.Series.value_counts).fillna(0).astype(int)\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform target column values ​​into 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = {'CONFIRMED': 0, 'FALSE POSITIVE': 1}\n",
    "local_view['label'] = local_view['label'].map(target_map)\n",
    "global_view['label'] = global_view['label'].map(target_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= Separating into X and y =============\n",
    "\n",
    "X_local = local_view.iloc[:, :-1]\n",
    "X_global = global_view.iloc[:, :-1]\n",
    "\n",
    "y_local = local_view['label']\n",
    "y_global = global_view['label']\n",
    "\n",
    "# ============= Separating into training and testing =============\n",
    "\n",
    "X_train_local, X_test_local, y_train_local, y_test_local = train_test_split(\n",
    "    X_local, y_local, test_size= 0.3, random_state=42, stratify=y_local)\n",
    "\n",
    "X_train_global, X_test_global, y_train_global, y_test_global = train_test_split(\n",
    "    X_global, y_global, test_size= 0.3, random_state=42, stratify=y_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smote balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smote balancing\n",
    "smote = SMOTE()  # Create a SMOTE instance\n",
    "X_train_local, y_train_local = smote.fit_resample(X_train_local, y_train_local)  # Apply SMOTE to data local\n",
    "X_train_global, y_train_global = smote.fit_resample(X_train_global, y_train_global)  # Apply SMOTE to data global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All models and parameters of classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_parameters_C = {\n",
    "    'AdaBoostClassifier': {\n",
    "        'clf': AdaBoostClassifier(random_state=42),\n",
    "        'parameters': {\n",
    "            'n_estimators': range(60, 220, 40)\n",
    "        },\n",
    "    },\n",
    "    'XGBClassifier': {\n",
    "        'clf': xgb.XGBClassifier(objective = \"binary:logistic\", random_state=42),\n",
    "        'parameters': {\n",
    "            'min_child_weight': [1, 5, 10],\n",
    "            'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "            'max_depth': [3, 4, 5]\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'clf': SVC(probability=True, random_state=42),\n",
    "        'parameters': {\n",
    "            'C': [1, 3, 5, 10, 15],\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'tol': [1e-3, 1e-4]\n",
    "        },\n",
    "    },\n",
    "    'MLPClassifier': {\n",
    "        'clf': MLPClassifier(random_state=42),\n",
    "        'parameters': {\n",
    "            'solver': ['sgd', 'adam'], \n",
    "            'max_iter': [1000, 1300, 1500, 2000], \n",
    "            'alpha': 10.0 ** -np.arange(1, 10), \n",
    "            'hidden_layer_sizes':np.arange(10, 15),\n",
    "            'tol': [1e-3, 1e-4]\n",
    "        },\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.defining_classifiers(models_and_parameters_C, X_train_local, y_train_local, X_test_local, y_test_local, \"local\")\n",
    "# models.defining_classifiers(models_and_parameters_C, X_train_global, y_train_global, X_test_global, y_test_global, \"global\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "label                                                                         \n",
      "0      1.837927  1.802662  1.232059  1.512449  1.569320  1.405640  1.000000   \n",
      "0      1.000000  1.476023  2.462279  1.453719  1.024518  1.866817  1.159148   \n",
      "0      1.078824  1.181373  2.207187  1.587193  0.980563  0.577552  1.163036   \n",
      "0      1.081321  1.580252  0.362759  0.644941  0.309738  0.704545  1.099352   \n",
      "0      0.680829  0.319184 -0.042460 -0.404105 -0.765749 -0.415386 -0.065023   \n",
      "\n",
      "              7         8         9  ...       191       192       193  \\\n",
      "label                                ...                                 \n",
      "0      1.496697  0.705534  1.123828  ...  1.601433  1.375619  1.492625   \n",
      "0      1.171658  2.225083  2.339150  ...  1.587496 -0.104021  0.708417   \n",
      "0      1.401895  2.084558  0.594387  ...  1.928679  0.972320  1.613166   \n",
      "0      1.028856  0.958360  0.887864  ...  1.378002  1.048320  2.519353   \n",
      "0      0.285340  0.635703  0.986067  ...  1.318989  1.396417  1.473845   \n",
      "\n",
      "            194       195       196       197       198       199       200  \n",
      "label                                                                        \n",
      "0      1.445211  1.380684  1.362785  1.916510  1.369103  1.416069  1.081608  \n",
      "0      2.168780  0.985443  1.935433  1.096555  0.834368  0.359093  1.717915  \n",
      "0      2.017149  1.602650  0.453598  1.042030  1.886965  1.244905  1.336639  \n",
      "0     -0.161869  0.843370  0.423355  0.003339  2.488378  1.755441  1.723028  \n",
      "0      1.551273  1.551273  1.551273  1.551273  1.551273  1.551273  1.551273  \n",
      "\n",
      "[5 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_local.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_local.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array list, no caso seria -> 201 instancias + label + 201 instancias + label + ...\n",
    "\n",
    "# uni_data = [[1.837927  1.802662  1.232059  1.512449 LABEL(1 or 0) 1.569320  1.405640  1.000000 1.551273 LABEL(1 or 0)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As variáveis abaixo garantem padronização e reprodutibilidade\n",
    "\n",
    "TRAIN_SPLIT = 300000\n",
    "\n",
    "# calcular numero de linhas \n",
    "# 7383 * 201 = 1.483.983 \n",
    "# Separa em um numero de linhas para treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 6030 into shape (30,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m univariate_past_history \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m  \u001b[39m#30 observacoes anteriores\u001b[39;00m\n\u001b[0;32m      3\u001b[0m future \u001b[39m=\u001b[39m univariate_future_target \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m  \u001b[39m#a proxima observação\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m x_train_uni, y_train_uni \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39;49munivariate_data(uni_data, \u001b[39m0\u001b[39;49m, TRAIN_SPLIT,\n\u001b[0;32m      6\u001b[0m                                         univariate_past_history,\n\u001b[0;32m      7\u001b[0m                                         univariate_future_target)\n\u001b[0;32m      8\u001b[0m x_val_uni, y_val_uni \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39munivariate_data(uni_data, TRAIN_SPLIT, \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m                                     univariate_past_history,\n\u001b[0;32m     10\u001b[0m                                     univariate_future_target)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Test LSTM data local\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alex-\\Desktop\\Dev\\Exoplanet-Detection-Algorithm\\MachineLearning\\models.py:133\u001b[0m, in \u001b[0;36munivariate_data\u001b[1;34m(dataset, start_index, end_index, history_size, target_size)\u001b[0m\n\u001b[0;32m    131\u001b[0m     indices \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(i\u001b[39m-\u001b[39mhistory_size, i)\n\u001b[0;32m    132\u001b[0m     \u001b[39m# Reshape data from (history_size,) to (history_size, 1)\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     data\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39;49mreshape(dataset[indices], (history_size, \u001b[39m1\u001b[39;49m)))\n\u001b[0;32m    134\u001b[0m     labels\u001b[39m.\u001b[39mappend(dataset[i\u001b[39m+\u001b[39mtarget_size])\n\u001b[0;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(data), np\u001b[39m.\u001b[39marray(labels)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(a, newshape, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    200\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mreshape\u001b[39;49m\u001b[39m'\u001b[39;49m, newshape, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[1;32mc:\\Users\\alex-\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 6030 into shape (30,1)"
     ]
    }
   ],
   "source": [
    "'''Tamanho da Janela do Historico'''\n",
    "univariate_past_history = 201 \n",
    "future = univariate_future_target = 1\n",
    "\n",
    "x_train_uni, y_train_uni = models.univariate_data(uni_data, 0, TRAIN_SPLIT,\n",
    "                                        univariate_past_history,\n",
    "                                        univariate_future_target)\n",
    "x_val_uni, y_val_uni = models.univariate_data(uni_data, TRAIN_SPLIT, None,\n",
    "                                    univariate_past_history,\n",
    "                                    univariate_future_target)\n",
    "\n",
    "\n",
    "# Test LSTM data local\n",
    "models.method_LSTM(x_train_uni, y_train_uni, x_val_uni, y_val_uni)\n",
    "\n",
    "# Test LSTM data global\n",
    "# models.method_LSTM(x_train_uni, y_train_uni, x_val_uni, y_val_uni)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
